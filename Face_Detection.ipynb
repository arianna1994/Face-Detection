{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZqM4uuAJlDHmYUXxPBGTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arianna1994/Face-Detection/blob/main/Face_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Detection per Fotocamere Digitali\n",
        "\n",
        "### Per il progetto sono stati definiti due set di dati, uno per l'addestramento e uno per il test. Per ognuno dei due set sono state predisposte due cartelle separate, una conetenete le foto con facce di persone e una contenente le foto sonza facce di persone.\n",
        "### Una volta addestrato il modello di classificazione che prevede due classi (\"altro\" e \"facce\"), utilizzo l'algoritmo Haar Cascade per individuare le posizioni dei visi delle persone nelle immagini che sono state classificate con la lable \"facce\".\n",
        "\n",
        "### I dataset utilizzati sono stati scaricati da Kaggle"
      ],
      "metadata": {
        "id": "l_3pnaL-caVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install img2vec_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUvZ6jckcWWY",
        "outputId": "3b7526c2-4698-4993-b0cd-e66f0ec708ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting img2vec_pytorch\n",
            "  Downloading img2vec_pytorch-1.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from img2vec_pytorch) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from img2vec_pytorch) (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from img2vec_pytorch) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (2024.6.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->img2vec_pytorch) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->img2vec_pytorch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->img2vec_pytorch) (1.3.0)\n",
            "Downloading img2vec_pytorch-1.0.1-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: img2vec_pytorch\n",
            "Successfully installed img2vec_pytorch-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importo librerie utili"
      ],
      "metadata": {
        "id": "AC5QNmZzfJZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XytfbrzXcC9a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.pipeline import Pipeline\n",
        "from img2vec_pytorch import Img2Vec\n",
        "from PIL import Image\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparo il set di addestramento e il set di test"
      ],
      "metadata": {
        "id": "ZIq1-g4Af1rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img2vec = Img2Vec()\n",
        "\n",
        "data_dir = \"/content/\"\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "data = {}\n",
        "for j, dir_ in enumerate([train_dir, val_dir]):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for category in os.listdir(dir_):\n",
        "        for img_path in os.listdir(os.path.join(dir_, category)):\n",
        "            img_path_ = os.path.join(dir_, category, img_path)\n",
        "            img = Image.open(img_path_)\n",
        "\n",
        "            img_features = img2vec.get_vec(img)\n",
        "\n",
        "            features.append(img_features)\n",
        "            labels.append(category)\n",
        "\n",
        "    data[['training_data', 'validation_data'][j]] = features\n",
        "    data[['training_labels', 'validation_labels'][j]] = labels\n"
      ],
      "metadata": {
        "id": "Sot0cCE1fqbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definisco il modello utilizzando l'algoritmo RandomForestClassifier"
      ],
      "metadata": {
        "id": "2-uxqLb1nd6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creo Pipeline\n",
        "my_pipe = Pipeline(\n",
        "    steps=[\n",
        "        ('classifier', RandomForestClassifier(random_state=0))\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "UFTcxmi8nN56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Addestro il modello per la classificazione delle immagini\n",
        "my_pipe.fit(data['training_data'], data['training_labels'])\n",
        "\n",
        "# Verifico le performance del modello\n",
        "y_pred = my_pipe.predict(data['validation_data'])\n",
        "score = accuracy_score(y_pred, data['validation_labels'])\n",
        "\n",
        "#L'accuracy Ã¨ molto alta\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSql3A6Cnk3F",
        "outputId": "fbfab6b2-1cef-406a-a340-b8669048f7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9893333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applicazione del modello"
      ],
      "metadata": {
        "id": "dhRX_bTDn4HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applico il modello di classificazione su un immagine\n",
        "img_path_es = \"/content/test/facce/00001943.jpg\"\n",
        "img_es = Image.open(img_path_es)\n",
        "\n",
        "img_es_ = img2vec.get_vec(img_es)\n",
        "list_t = []\n",
        "list_t.append(img_es_)\n",
        "\n",
        "#Applico il modello di classificazione sull'immagine in analisi\n",
        "y_pred = my_pipe.predict(list_t)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlrDRj_3n8cy",
        "outputId": "9e59fd51-2705-4034-810f-990e7f10735d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['facce'], dtype='<U5')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importo l'algoritmo per la face detection\n",
        "face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_alt.xml')\n",
        "\n",
        "#applico la face detection solo se la foto viene classificata come \"facce\" dal modello di classificazione\n",
        "if y_pred[0] == \"facce\":\n",
        "    img=cv2.imread(img_path_es)\n",
        "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray=cv2.equalizeHist(gray)\n",
        "    faces=face_cascade.detectMultiScale(gray, 1.25,15)\n",
        "    print('Le facce sono', len(faces), '\\nLe coordinate sono', '\\n',faces)\n",
        "else:\n",
        "    print(\"Nessuna faccia rilevata\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0tIlWdLoVMc",
        "outputId": "1e5e44a7-64f8-4c6e-a656-61d810e37fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le facce sono 5 \n",
            "Le coordinate sono \n",
            " [[145  94 133 133]\n",
            " [555  97 142 142]\n",
            " [289 184 141 141]\n",
            " [870 188 174 174]\n",
            " [718 196 134 134]]\n"
          ]
        }
      ]
    }
  ]
}